{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model Using vec2vec lstm\n",
    "- seq2seq lstm\n",
    "- cnn + lstm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.api.types import is_timedelta64_dtype\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data_pos.csv')\n",
    "df_copy = test.copy()\n",
    "df_copy.transacted_date = pd.to_datetime(df_copy.transacted_date)\n",
    "print(\"done\")\n",
    "\n",
    "df = df_copy\n",
    "test_groupby_date_store = df.groupby(['transacted_date', 'store_id'])['amount'].sum()\n",
    "test_groupby_date_store = test_groupby_date_store.reset_index()\n",
    "test_groupby_date_store = test_groupby_date_store.set_index('transacted_date')\n",
    "store_list = test_groupby_date_store.store_id.unique()\n",
    "store_list.sort()\n",
    "store_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = datetime(2018,12,1)\n",
    "test_end = datetime(2019,2,28)\n",
    "\n",
    "# print(test_groupby_date_store.head())\n",
    "ts_train = test_groupby_date_store[test_groupby_date_store.index<test_start]\n",
    "ts_test = test_groupby_date_store[test_groupby_date_store.index>=test_start]\n",
    "ts_test = ts_test[ts_test.index<test_end]\n",
    "\n",
    "# train test 개수가 적합한지 확인\n",
    "threshold = (test_start - datetime(2016,6,1)).days\n",
    "ts_train_number = ts_train.groupby(['store_id']).count()\n",
    "ts_train_number = ts_train_number[ts_train_number.amount>0.5*threshold]\n",
    "store_list_train = ts_train_number.index.unique()\n",
    "threshold2 = (test_end - test_start).days\n",
    "ts_test_number = ts_test.groupby(['store_id']).count()\n",
    "ts_test_number = ts_test_number[ts_test_number.amount>0.5*threshold2]\n",
    "store_list_test = ts_test_number.index.unique()\n",
    "store_list = [store_id for store_id in store_list_test if store_id in store_list_train]\n",
    "print(\"store list size\",len(store_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(threshold2)\n",
    "true_sum = {}\n",
    "for store_id in store_list[:]:\n",
    "    \n",
    "    sales = ts_test[ts_test.store_id==store_id].amount\n",
    "    true_sum[store_id]=sales.sum()*(threshold2/sales.count())\n",
    "test_sum = {}\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def split_data(data, n_steps_in, n_steps_out):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-n_steps_in-n_steps_out):\n",
    "        a = dataset[i:(i+n_steps_in)]\n",
    "        X.append(a)\n",
    "        y.append(dataset[i+n_steps_in:i+n_steps_in+n_steps_out].sum())\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# def split_data(data):\n",
    "#     X, y = [], []\n",
    "#     for i in range(len(data)-7-7):\n",
    "#         a = data[i:(i+7)]\n",
    "#         b = data[i:(i+14)].sum()\n",
    "#         c = data[i:(i+28)].sum()\n",
    "#         a = np.std(data[i:(i+7)])\n",
    "#         b = np.std(data[i:(i+14)])\n",
    "#         c = np.std(data[i:(i+28)])\n",
    "#         X.append([a])\n",
    "#         y.append(dataset[i+28:i+28+92].sum())\n",
    "#         y.append(dataset[i+7:i+7+7])\n",
    "\n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "for store_id in store_list[:1]:\n",
    "    prediction_i = None    \n",
    "    test_df = ts_train[ts_train.store_id==store_id]\n",
    "    dataset = test_df.values\n",
    "    dataset = dataset.astype('float64')\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    dataset = dataset[:,1]\n",
    "    \n",
    "    n_steps_in = 7\n",
    "    n_steps_out = 7\n",
    "    X,y = split_data(dataset,n_steps_in,n_steps_out)\n",
    "    n_features = 1\n",
    "    X = X.reshape((X.shape[0],n_steps_in,n_features))\n",
    "    \n",
    "#     y = y.reshape((y.shape[0], y.shape[1], 1))\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_steps_in,n_features)))\n",
    "#     model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(RepeatVector(n_steps_out))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_features))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X,y, epochs=50, batch_size=1, verbose=2)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_sum = []\n",
    "true_sum = []\n",
    "\n",
    "for i in range(1):\n",
    "    x_input = X[i]\n",
    "    x_input = x_input.reshape((1,n_steps_in,n_features))\n",
    "    model.predict(x_input, verbose=2)\n",
    "    true_sum.append([0,y[i].sum()])\n",
    "    pre_sum.append([0,yhat.sum()])\n",
    "\n",
    "\n",
    "pre_sum = scaler.inverse_transform(pre_sum)\n",
    "true_sum = scaler.inverse_transform(true_sum)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(pre_sum[:,1],true_sum[:,1])\n",
    "print(\"mae\",mae)\n",
    "\n",
    "plt.figure(figsize=(22,10))\n",
    "plt.plot(true_sum[:],label = \"true_sum\")\n",
    "plt.plot(pre_sum[:],label = \"predict_sum\")\n",
    "plt.title(\"lstm\")\n",
    "plt.xlabel(\"case\")\n",
    "plt.ylabel(\"3month amount\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_data(data):\n",
    "    X = []\n",
    "    for i in range(0,len(data)-28*3,28*3):\n",
    "        X.append(data[i:i+28*3].sum())\n",
    "    return np.array(X)\n",
    "\n",
    "prediction_i = None    \n",
    "test_df = ts_train[ts_train.store_id==1104]\n",
    "# print(test_df)\n",
    "dataset = test_df.values\n",
    "dataset = dataset.astype('float64')\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "dataset = dataset[:,1]\n",
    "\n",
    "X = monthly_data(dataset)\n",
    "X\n",
    "plt.figure(figsize=(22,10))\n",
    "plt.plot(X,label = \"monthly\")\n",
    "plt.title(\"lstm\")\n",
    "plt.xlabel(\"case\")\n",
    "plt.ylabel(\"3month amount\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
